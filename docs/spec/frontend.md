# Moire Frontend Specification

The Moire dashboard is a React/TypeScript single-page application served by `moire-web`. It communicates with the server exclusively over HTTP using a JSON REST API. All shared types are generated from Rust definitions — no type is hand-authored on both sides.

---

## Type Generation

> r[types.gen.source]
> All TypeScript types shared between the server and the dashboard MUST be generated from Rust struct/enum definitions annotated with `#[derive(Facet)]`. The canonical generated file is `frontend/src/api/types.generated.ts`.

> r[types.gen.tool]
> The generator binary is `cargo run -p moire-web --bin gen_frontend_types`. It MUST be re-run whenever the underlying Rust types change. The generated file MUST NOT be edited by hand.

> r[types.gen.header]
> The generated file MUST begin with the comment `// @generated by cargo run -p moire-web --bin gen_frontend_types` followed by `// Do not edit by hand.`.

---

## HTTP API

The `ApiClient` interface is the authoritative contract between the dashboard and the server. Every method maps to one HTTP endpoint.

### Connections

> r[api.connections]
> `GET /api/connections` returns a `ConnectionsResponse` listing every process currently connected to the dashboard over TCP, including `conn_id`, `process_name`, and `pid` for each.

### Snapshots

> r[api.snapshot.trigger]
> `POST /api/snapshot` immediately assembles and returns a `SnapshotCutResponse` from all connected processes that reply within the timeout window. Processes that time out are listed in `timed_out_processes`.

> r[api.snapshot.current]
> `GET /api/snapshot/current` returns the most recent `SnapshotCutResponse` if one exists, or HTTP 404 if no snapshot has been taken yet.

### Cuts

> r[api.cuts.trigger]
> `POST /api/cuts` initiates a coordinated cut: it sends a snapshot request to all connected processes and returns a `TriggerCutResponse` containing a `cut_id` and the number of processes requested.

> r[api.cuts.status]
> `GET /api/cuts/{cut_id}` returns a `CutStatusResponse` showing how many connections have acknowledged (`acked_connections`) vs. are still pending (`pending_connections`). The client MUST poll this endpoint until all connections are acked or a timeout elapses.

### Recording

> r[api.record.start]
> `POST /api/record/start` begins a recording session. The request body is a `RecordStartRequest` with optional fields `interval_ms`, `max_frames`, and `max_memory_bytes`. Returns a `RecordingSessionInfo` describing the newly started session.

> r[api.record.stop]
> `POST /api/record/stop` stops the active recording session and returns a `RecordingSessionInfo` reflecting the final state.

> r[api.record.current]
> `GET /api/record/current` returns a `RecordCurrentResponse`. The `session` field is present if a session exists (recording or stopped), absent otherwise.

> r[api.record.frame]
> `GET /api/record/current/frame/{frameIndex}` returns a `SnapshotCutResponse` for the frame at the given index. The frame index is zero-based and MUST be within `[0, frame_count)`.

> r[api.record.export]
> `GET /api/record/current/export` returns the full recording as a binary blob (`RecordingImportBody` serialized to a well-defined format). The `Content-Type` MUST allow the browser to download it as a file.

> r[api.record.import]
> `POST /api/record/import` accepts a previously exported recording file and restores it as the current session. Returns a `RecordingSessionInfo` on success.

### Diagnostics

> r[api.sql]
> `POST /api/sql` executes a raw SQL query against the dashboard's SQLite database and returns a `SqlResponse` with `columns`, `rows`, and `row_count`. This endpoint is intended for debugging only.

---

## Display Data Model

The dashboard converts raw wire types into richer display types before rendering. This conversion is pure and deterministic — the same wire snapshot always produces the same display data.

### Composite IDs

> r[display.id.composite]
> Every entity on the display side has a composite ID of the form `"${process_id}/${raw_entity_id}"`. This string uniquely identifies an entity across all connected processes in a single snapshot.

> r[display.id.scope-key]
> Every scope on the display side has a composite key of the form `"${process_id}:${scope_id}"`.

### Source resolution

> r[display.source.strict]
> Source IDs MUST be resolved against the `sources` array in each process snapshot. If a `SourceId` is not present in the map, or the resolved `SnapshotSource` has a missing/empty `path`, a non-positive `line`, or a missing/empty `krate`, snapshot conversion MUST throw with an explicit error message identifying the process and the context (entity, scope, or edge). Silent fallback to placeholder values is not permitted.

### Backtrace IDs

> r[display.backtrace.required]
> Every entity and scope in a snapshot MUST carry a `backtrace_id` field that is a positive integer. If the field is absent, zero, or non-integer, conversion MUST throw with an explicit error message. This field will be used to resolve call stacks once backtrace capture is fully specified.

### Tone

> r[display.tone]
> A `Tone` is one of four string values: `"ok"`, `"warn"`, `"crit"`, `"neutral"`. It is used to color-code status badges and stat indicators throughout the UI.

### EntityDef

> r[display.entity]
> An `EntityDef` is the dashboard-side representation of an entity. It carries:
> - `id`: composite entity ID
> - `rawEntityId`: the original ID as reported by the process
> - `processId`, `processName`, `processPid`: process identity
> - `name`: human-facing label
> - `kind`: the first key of `body` (e.g. `"future"`, `"lock"`, `"mpsc_tx"`)
> - `body`: the raw `EntityBody` from the wire
> - `backtraceId`: resolved backtrace ID
> - `source`: resolved `SnapshotSource`
> - `krate`: the `krate` field of the resolved source
> - `birthPtime`: `PTime` when the entity was first registered
> - `ageMs`: `max(0, ptime_now_ms - birthPtime)` at capture time
> - `birthApproxUnixMs`: approximate wall-clock birth computed as `(captured_at_unix_ms - ptime_now_ms) + birthPtime`
> - `meta`: arbitrary display metadata (populated by entity-kind-specific logic)
> - `inCycle`: whether this entity participates in a `waiting_on` deadlock cycle
> - `status`: derived `{ label: string; tone: Tone }` (see below)
> - `stat`: optional short fill-indicator string (e.g. `"3/8"`)
> - `statTone`: optional `Tone` for the stat indicator

### Status derivation

> r[display.entity.status]
> The `status` of an `EntityDef` is derived from its `body` according to the following rules, applied in order:
> - `future` → `{ label: "polling", tone: "neutral" }`
> - `request` → `{ label: "in_flight", tone: "warn" }`
> - `response` with `ok` status → `{ label: "ok", tone: "ok" }`
> - `response` with `error` status → `{ label: "error", tone: "crit" }`
> - `response` with `cancelled` status → `{ label: "cancelled", tone: "neutral" }`
> - `response` with `pending` status → `{ label: "pending", tone: "warn" }`
> - `lock` → `{ label: "held", tone: "crit" }`
> - `mpsc_tx`, `mpsc_rx`, `broadcast_tx`, `watch_tx`, `watch_rx` → `{ label: "active", tone: "ok" }`
> - `broadcast_rx` with `lag > 0` → `{ label: "lag: ${lag}", tone: "warn" }`
> - `broadcast_rx` with `lag == 0` → `{ label: "active", tone: "ok" }`
> - `oneshot_tx` with `sent == true` → `{ label: "sent", tone: "ok" }`
> - `oneshot_tx` with `sent == false` → `{ label: "pending", tone: "neutral" }`
> - `oneshot_rx` → `{ label: "waiting", tone: "neutral" }`
> - `semaphore` → `{ label: "${available}/${max_permits} permits", tone: "warn" }` if any permits are held, `"ok"` otherwise
> - `notify` → `{ label: "waiting", tone: "neutral" }`
> - `once_cell` with `initialized` → `{ label: "initialized", tone: "ok" }`
> - `once_cell` with `initializing` → `{ label: "initializing", tone: "warn" }`
> - `once_cell` with `empty` → `{ label: "empty", tone: "neutral" }`
> - `command` → `{ label: "running", tone: "neutral" }`
> - `file_op` → `{ label: op, tone: "ok" }`
> - `net_connect`, `net_accept`, `net_read`, `net_write` → `{ label: "connected", tone: "ok" }`
> - fallback → `{ label: "unknown", tone: "neutral" }`

### Stat derivation

> r[display.entity.stat]
> The `stat` string is a short fill indicator shown on nodes that carry a quantitative capacity measurement:
> - `semaphore` → `"${max_permits - handed_out_permits}/${max_permits}"`
> - `mpsc_tx` → `"${queue_len}/${capacity ?? "∞"}"`
> - `notify` with `waiter_count > 0` → `"${waiter_count} waiters"`
> - `once_cell` with `waiter_count > 0` → `"${waiter_count} waiter"`
> - all other kinds → absent (`undefined`)

> r[display.entity.stat-tone]
> The `statTone` is set for `mpsc_tx` only:
> - If `queue_len >= capacity`: `"crit"`
> - If `queue_len / capacity >= 0.75`: `"warn"`
> - Otherwise: absent

### EdgeDef

> r[display.edge]
> An `EdgeDef` is the dashboard-side representation of an edge. It carries:
> - `id`: a stable string ID of the form `"e${i}-${srcComposite}-${dstComposite}-${kind}"`
> - `source`: composite entity ID of the source
> - `target`: composite entity ID of the destination
> - `kind`: the wire `EdgeKind`
> - `sourcePort`: optional ELK port ID on the source node, used when the source is a merged pair node
> - `targetPort`: optional ELK port ID on the target node, used when the target is a merged pair node

### ScopeDef

> r[display.scope]
> A `ScopeDef` is the dashboard-side representation of a scope. It carries:
> - `key`: composite scope key (`"${processId}:${scopeId}"`)
> - `processId`, `processName`, `processPid`
> - `scopeId`, `scopeName`
> - `scopeKind`: canonical kind string (`"process"`, `"thread"`, `"task"`, `"connection"`)
> - `backtraceId`
> - `source`: resolved `SnapshotSource`
> - `krate`
> - `birthPtime`, `ageMs`
> - `memberEntityIds`: list of composite entity IDs currently associated with this scope

---

## Snapshot Conversion Pipeline

> r[convert.order]
> Raw `SnapshotCutResponse` wire data is converted to display data through the following ordered pipeline:
> 1. Collect all entities and edges across all processes, resolving source IDs and backtrace IDs strictly.
> 2. Build a raw-entity-ID-to-composite-ID lookup for cross-process edge resolution.
> 3. Resolve edges: for `paired_with` edges, the `src` is looked up in the global raw-ID map (cross-process); for all other kinds, `src` is scoped to the current process.
> 4. Merge channel pairs (`mergeChannelPairs`).
> 5. Merge RPC pairs (`mergeRpcPairs`).
> 6. Coalesce redundant `polls` edges (`coalesceContextEdges`).
> 7. Detect deadlock cycle membership (`detectCycleNodes`), marking `inCycle` on all entities in a cycle.

---

## Graph Node Merging

### Channel pair merging

> r[merge.channel]
> When a `paired_with` edge connects a TX entity (kind in `{mpsc_tx, broadcast_tx, watch_tx, oneshot_tx}`) to an RX entity (kind in `{mpsc_rx, broadcast_rx, watch_rx, oneshot_rx}`), the two nodes and the connecting edge MUST be replaced by a single synthetic `channel_pair` node.

> r[merge.channel.id]
> The merged node's ID MUST be `"pair:${txId}:${rxId}"`. The TX port ID MUST be `"${mergedId}:tx"` and the RX port ID MUST be `"${mergedId}:rx"`. Any edge that formerly connected to the TX or RX entity MUST be remapped to the merged node with the appropriate port ID.

> r[merge.channel.name]
> The merged node's name is derived from the TX entity's name: if it ends with `":tx"`, that suffix is stripped.

> r[merge.channel.status]
> The merged node's status is `{ label: "open", tone: "ok" }` if both component statuses have tone `"ok"`, and `{ label: "closed", tone: "neutral" }` otherwise. The merged node's `stat` and `statTone` are taken from the TX entity.

> r[merge.channel.guard]
> A TX or RX entity that is already part of a merged pair MUST NOT be merged a second time. Each channel endpoint participates in at most one merge.

### RPC pair merging

> r[merge.rpc]
> When a `paired_with` edge connects a `request` entity to a `response` entity (in either direction), and both belong to the same group under the active `groupBy` mode, the two nodes and the connecting edge MUST be replaced by a single synthetic `rpc_pair` node.

> r[merge.rpc.id]
> The merged node's ID MUST be `"rpc_pair:${reqId}:${respId}"`. The request port ID MUST be `"${mergedId}:req"` and the response port ID MUST be `"${mergedId}:resp"`. Any edge formerly connected to either component MUST be remapped to the merged node with the appropriate port ID.

> r[merge.rpc.name]
> The merged node's name is derived from the request entity's name: if it ends with `":req"`, that suffix is stripped.

> r[merge.rpc.status]
> The merged node's status is taken from the response entity if the response body is present, or `{ label: "in_flight", tone: "warn" }` if the response has no body.

> r[merge.rpc.group]
> If the request and response entities belong to different groups under the active `groupBy` mode, they MUST NOT be merged.

### Edge coalescing

> r[merge.coalesce]
> After channel and RPC pairs are merged, if a `polls` edge and any other edge kind both connect the same source-target pair, the `polls` edge MUST be suppressed. The richer structural or causal edge takes precedence.

### Deadlock cycle detection

> r[merge.cycles]
> After all merges, the `waiting_on` edges are traversed with DFS to find strongly-connected components. Every entity whose ID appears in a cycle MUST have `inCycle` set to `true`. Entities not in any cycle MUST have `inCycle` set to `false`.

---

## Graph Filtering

The graph filter is a space-separated list of tokens parsed from a single text input. Each token has the form `[sign]key:value`.

### Token syntax

> r[filter.token.syntax]
> A filter token has the form `[sign]key:value` where `sign` is `+` or `-` (absent means unsigned). Values may be double-quoted to include spaces or special characters. Within a quoted value, `\"` and `\\` are escape sequences.

> r[filter.token.tokenize]
> Tokens are separated by whitespace. Whitespace inside a quoted value does not split tokens. An unmatched `+` or `-` prefix with no key-value following it is not a valid token.

### Signed filter tokens (inclusion/exclusion)

Signed tokens form an allowlist (`+`) or denylist (`-`). Multiple tokens of the same sign and axis combine as a union (OR). If any `+` token is present for an axis, only entities matching at least one of the `+` values on that axis are shown.

> r[filter.axis.node]
> `+node:<id>` / `-node:<id>` — include or exclude the entity with the given composite ID. The key may also be spelled `id`.

> r[filter.axis.location]
> `+location:<src>` / `-location:<src>` — include or exclude entities whose source resolves to the given `"path:line"` string. The key may also be spelled `source`.

> r[filter.axis.crate]
> `+crate:<name>` / `-crate:<name>` — include or exclude entities whose source `krate` matches the given name.

> r[filter.axis.process]
> `+process:<id>` / `-process:<id>` — include or exclude entities belonging to the process with the given `processId` string.

> r[filter.axis.kind]
> `+kind:<kind>` / `-kind:<kind>` — include or exclude entities whose canonical kind matches the given string.

### Unsigned control tokens

> r[filter.control.focus]
> `focus:<id>` (also `subgraph:<id>`) — after all axis filters are applied, restrict the visible graph to the connected subgraph reachable from the entity with the given composite ID via any edge in either direction (BFS). Entities not reachable from the focus node are hidden.

> r[filter.control.loners]
> `loners:on` / `loners:off` — when `off`, entities that have no edges to any other visible entity MUST be hidden from the graph. The default behavior (no token) is equivalent to `loners:on`.

> r[filter.control.colorby]
> `colorBy:process` / `colorBy:crate` — color entity nodes by their process or crate membership. When absent, all nodes use the default color.

> r[filter.control.groupby]
> `groupBy:process` / `groupBy:crate` — render entities inside labeled subgraph boxes grouped by process or crate. `groupBy:none` removes grouping. Grouping also affects RPC pair merging: request and response entities in different groups are not merged.

> r[filter.control.labelby]
> `labelBy:process` / `labelBy:crate` / `labelBy:location` — display a secondary label on each entity card showing the process name, crate name, or source location respectively.

### Filter application order

> r[filter.order]
> Filters MUST be applied in the following order:
> 1. Apply signed axis filters (include/exclude by node, location, crate, process, kind).
> 2. Collapse edges through any newly-hidden nodes (see `f[graph.collapse]`).
> 3. If `loners:off`, remove entities with no remaining edges.
> 4. If a `focus` token is present, restrict to the connected subgraph of the focus node.

### Edge collapsing through hidden nodes

> r[graph.collapse]
> When entities are hidden by filtering, any edge that passed through a hidden node would disappear from the graph, potentially breaking the visual path between visible nodes. To preserve connectivity: for each pair of visible nodes that are connected through one or more hidden intermediate nodes (following any edge in either direction), a synthetic `polls` edge MUST be created between them, unless a direct visible edge already exists between that pair.

> r[graph.collapse.id]
> A synthetic collapsed edge MUST have ID `"collapsed-${left}-${right}"` where `left` and `right` are the lexicographically ordered source and target IDs.

> r[graph.collapse.no-dup]
> A synthetic collapsed edge MUST NOT be created if a direct visible edge already connects that same node pair.

### Autocomplete

> r[filter.suggest]
> The filter input MUST provide autocomplete suggestions based on the current draft token. Suggestions are ranked by prefix match, substring match, and fuzzy subsequence match (in that order). Suggestions that are already present as committed tokens MUST be omitted.

> r[filter.suggest.fragment]
> Suggestions are generated against the in-progress fragment (the token currently being typed). When the fragment is empty or has no `:`, top-level operator and control tokens are suggested. When the fragment begins with `+` or `-` and no `:`, signed axis key suggestions are offered. When a `:` is present, value completions for the given key are offered using available entity IDs, locations, crates, process IDs, and kinds.

---

## Recording

### Session lifecycle

> r[recording.lifecycle]
> The recording session follows a strict state machine:
> - **idle**: no session exists. `GET /api/record/current` returns no `session`.
> - **recording**: a session is active. `status` is `"recording"`.
> - **stopped**: the session has ended. `status` is `"stopped"`. Frame data is available for scrubbing.

### Frame capture

> r[recording.frame]
> Each frame in a recording session is a complete `SnapshotCutResponse` captured at `interval_ms` milliseconds since the previous frame. A `FrameSummary` carries `frame_index`, `captured_at_unix_ms`, `process_count`, and `capture_duration_ms`.

### Union layout

> r[recording.union]
> To support frame scrubbing without re-laying-out on every frame, the dashboard MUST pre-compute a **union layout**: the union of all nodes and edges that appear in any processed frame. This union is laid out once by the graph layout engine. Node positions from the union layout are reused for all frames.

> r[recording.union.presence]
> For each node and each edge in the union, the set of frame indices in which it is present MUST be tracked. This enables efficient per-frame visibility queries.

> r[recording.union.ghost]
> In ghost mode, nodes and edges that exist in the union but are absent from the current frame MUST be rendered translucently ("ghost" style) at their union layout positions. This preserves spatial stability across frames.

> r[recording.union.downsample]
> The dashboard MAY downsample frames by processing only every N-th frame (plus first and last) to reduce fetch load. The downsample interval is configurable. Nearest-frame snapping MUST be used when displaying a scrub position that falls between processed frames.

### Frame change detection

> r[recording.changes]
> The dashboard MUST compute a list of frames in which the graph topology changed (nodes or edges appeared or disappeared relative to the previous processed frame). Only these change frames need to be represented as distinct scrub positions in the timeline.

### Export and import

> r[recording.export]
> A recording session MUST be exportable as a self-contained binary blob via `GET /api/record/current/export`.

> r[recording.import]
> An exported recording MAY be imported back into the dashboard via `POST /api/record/import`, replacing the current session.
