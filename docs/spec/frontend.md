# Moire Frontend Specification

The Moire dashboard is a React/TypeScript single-page application served by `moire-web`. It communicates with the server exclusively over HTTP using a JSON REST API. All shared types are generated from Rust definitions — no type is hand-authored on both sides.

---

## Type Generation

> r[types.gen.source]
> All TypeScript types shared between the server and the dashboard MUST be generated from Rust struct/enum definitions annotated with `#[derive(Facet)]`. The canonical generated file is `frontend/src/api/types.generated.ts`.

> r[types.gen.tool]
> The generator binary is `cargo run -p moire-web --bin gen_frontend_types`. It MUST be re-run whenever the underlying Rust types change. The generated file MUST NOT be edited by hand.

> r[types.gen.header]
> The generated file MUST begin with the comment `// @generated by cargo run -p moire-web --bin gen_frontend_types` followed by `// Do not edit by hand.`.

---

## HTTP API

The `ApiClient` interface is the authoritative contract between the dashboard and the server. Every method maps to one HTTP endpoint.

### Connections

> r[api.connections]
> `GET /api/connections` returns a `ConnectionsResponse` listing every process currently connected to the dashboard over TCP, including `conn_id`, `process_name`, and `pid` for each.

### Snapshots

> r[api.snapshot.trigger]
> `POST /api/snapshot` immediately assembles and returns a `SnapshotCutResponse` from all connected processes that reply within the timeout window. Processes that time out are listed in `timed_out_processes`.

> r[api.snapshot.current]
> `GET /api/snapshot/current` returns the most recent `SnapshotCutResponse` if one exists, or HTTP 404 if no snapshot has been taken yet.

### Cuts

> r[api.cuts.trigger]
> `POST /api/cuts` initiates a coordinated cut: it sends a snapshot request to all connected processes and returns a `TriggerCutResponse` containing a `cut_id` and the number of processes requested.

> r[api.cuts.status]
> `GET /api/cuts/{cut_id}` returns a `CutStatusResponse` showing how many connections have acknowledged (`acked_connections`) vs. are still pending (`pending_connections`). The client MUST poll this endpoint until all connections are acked or a timeout elapses.

> r[api.cuts.top-frames]
> Every `SnapshotCutResponse` MUST include a `top_frames` map from `BacktraceId` to resolved top application frame for every `BacktraceId` referenced in that cut. Backtraces with no top application frame are absent from the map. This map is populated after the server waits for symbolication to complete (see `r[symbolicate.cut-drain]`).

### Recording

> r[api.record.start]
> `POST /api/record/start` begins a recording session. The request body is a `RecordStartRequest` with optional fields `interval_ms`, `max_frames`, and `max_memory_bytes`. Returns a `RecordingSessionInfo` describing the newly started session.

> r[api.record.stop]
> `POST /api/record/stop` stops the active recording session and returns a `RecordingSessionInfo` reflecting the final state.

> r[api.record.current]
> `GET /api/record/current` returns a `RecordCurrentResponse`. The `session` field is present if a session exists (recording or stopped), absent otherwise.

> r[api.record.frame]
> `GET /api/record/current/frame/{frameIndex}` returns a `SnapshotCutResponse` for the frame at the given index. The frame index is zero-based and MUST be within `[0, frame_count)`.

> r[api.record.export]
> `GET /api/record/current/export` returns the full recording as a binary blob (`RecordingImportBody` serialized to a well-defined format). The `Content-Type` MUST allow the browser to download it as a file.

> r[api.record.import]
> `POST /api/record/import` accepts a previously exported recording file and restores it as the current session. Returns a `RecordingSessionInfo` on success.

### Diagnostics

> r[api.sql]
> `POST /api/sql` executes a raw SQL query against the dashboard's SQLite database and returns a `SqlResponse` with `columns`, `rows`, and `row_count`. This endpoint is intended for debugging only.

### Backtrace Resolution

> r[api.backtrace]
> `GET /api/connections/{conn_id}/backtraces/{backtrace_id}` returns a `BacktraceResponse` for the given `BacktraceId` within the identified connection. The server resolves each frame in the stored `BacktraceRecord` against the module's debug information and returns an ordered list of `ResolvedFrame` values. Each `ResolvedFrame` is either a resolved variant carrying `function_name` (demangled), `crate_name`, `module_path`, `source_file`, and optional `line` and `column`; or an unresolved variant carrying the raw `module_path` and `rel_pc` (as a hex string). The endpoint MUST NOT drop frames: every frame in the `BacktraceRecord` MUST appear in the response as either resolved or unresolved.

---

## Display Data Model

The dashboard converts raw wire types into richer display types before rendering. This conversion is pure and deterministic — the same wire snapshot always produces the same display data.

### Backtrace IDs

> r[display.backtrace.required+2]
> Every entity and scope in a snapshot MUST carry a `backtrace_id` field that is a positive integer. If the field is absent, zero, or non-integer, snapshot conversion MUST throw with an explicit error message identifying the process and the context (entity ID or scope ID). Silent fallback is not permitted.

### Tone

> r[display.tone]
> A `Tone` is one of four string values: `"ok"`, `"warn"`, `"crit"`, `"neutral"`. It is used to color-code status badges and stat indicators throughout the UI.

### EntityDef

> r[display.entity+2]
> An `EntityDef` is the dashboard-side representation of an entity. It carries:
> - `id`: the raw wire `EntityId`
> - `processId`, `processName`, `processPid`: process identity
> - `name`: human-facing label
> - `kind`: the first key of `body` (e.g. `"future"`, `"lock"`, `"mpsc_tx"`)
> - `body`: the raw `EntityBody` from the wire
> - `backtraceId`: the `BacktraceId` from the wire entity, as a positive integer
> - `birthPtime`: `PTime` when the entity was first registered
> - `ageMs`: `max(0, ptime_now_ms - birthPtime)` at capture time
> - `birthApproxUnixMs`: approximate wall-clock birth computed as `(captured_at_unix_ms - ptime_now_ms) + birthPtime`
> - `meta`: arbitrary display metadata (populated by entity-kind-specific logic)
> - `inCycle`: whether this entity participates in a `waiting_on` deadlock cycle
> - `status`: derived `{ label: string; tone: Tone }` (see below)
> - `stat`: optional short fill-indicator string (e.g. `"3/8"`)
> - `statTone`: optional `Tone` for the stat indicator

### Status derivation

> r[display.entity.status]
> The `status` of an `EntityDef` is derived from its `body` according to the following rules, applied in order:
> - `future` → `{ label: "polling", tone: "neutral" }`
> - `request` → `{ label: "in_flight", tone: "warn" }`
> - `response` with `ok` status → `{ label: "ok", tone: "ok" }`
> - `response` with `error` status → `{ label: "error", tone: "crit" }`
> - `response` with `cancelled` status → `{ label: "cancelled", tone: "neutral" }`
> - `response` with `pending` status → `{ label: "pending", tone: "warn" }`
> - `lock` → `{ label: "held", tone: "crit" }`
> - `mpsc_tx`, `mpsc_rx`, `broadcast_tx`, `watch_tx`, `watch_rx` → `{ label: "active", tone: "ok" }`
> - `broadcast_rx` with `lag > 0` → `{ label: "lag: ${lag}", tone: "warn" }`
> - `broadcast_rx` with `lag == 0` → `{ label: "active", tone: "ok" }`
> - `oneshot_tx` with `sent == true` → `{ label: "sent", tone: "ok" }`
> - `oneshot_tx` with `sent == false` → `{ label: "pending", tone: "neutral" }`
> - `oneshot_rx` → `{ label: "waiting", tone: "neutral" }`
> - `semaphore` → `{ label: "${available}/${max_permits} permits", tone: "warn" }` if any permits are held, `"ok"` otherwise
> - `notify` → `{ label: "waiting", tone: "neutral" }`
> - `once_cell` with `initialized` → `{ label: "initialized", tone: "ok" }`
> - `once_cell` with `initializing` → `{ label: "initializing", tone: "warn" }`
> - `once_cell` with `empty` → `{ label: "empty", tone: "neutral" }`
> - `command` → `{ label: "running", tone: "neutral" }`
> - `file_op` → `{ label: op, tone: "ok" }`
> - `net_connect`, `net_accept`, `net_read`, `net_write` → `{ label: "connected", tone: "ok" }`
> - fallback → `{ label: "unknown", tone: "neutral" }`

### Stat derivation

> r[display.entity.stat]
> The `stat` string is a short fill indicator shown on nodes that carry a quantitative capacity measurement:
> - `semaphore` → `"${max_permits - handed_out_permits}/${max_permits}"`
> - `mpsc_tx` → `"${queue_len}/${capacity ?? "∞"}"`
> - `notify` with `waiter_count > 0` → `"${waiter_count} waiters"`
> - `once_cell` with `waiter_count > 0` → `"${waiter_count} waiter"`
> - all other kinds → absent (`undefined`)

> r[display.entity.stat-tone]
> The `statTone` is set for `mpsc_tx` only:
> - If `queue_len >= capacity`: `"crit"`
> - If `queue_len / capacity >= 0.75`: `"warn"`
> - Otherwise: absent

### EdgeDef

> r[display.edge+2]
> An `EdgeDef` is the dashboard-side representation of an edge. It carries:
> - `id`: a stable string ID of the form `"e${i}-${src}-${dst}-${kind}"`
> - `source`: raw `EntityId` of the source
> - `target`: raw `EntityId` of the destination
> - `kind`: the wire `EdgeKind`
> - `sourcePort`: optional ELK port ID on the source node, used when the source is a merged pair node
> - `targetPort`: optional ELK port ID on the target node, used when the target is a merged pair node

### ScopeDef

> r[display.scope+2]
> A `ScopeDef` is the dashboard-side representation of a scope. It carries:
> - `id`: the raw wire `ScopeId`
> - `processId`, `processName`, `processPid`
> - `scopeName`
> - `scopeKind`: canonical kind string (`"process"`, `"thread"`, `"task"`, `"connection"`)
> - `backtraceId`: the `BacktraceId` from the wire scope, as a positive integer
> - `birthPtime`, `ageMs`
> - `memberEntityIds`: list of raw `EntityId` values currently associated with this scope

---

## Snapshot Conversion Pipeline

> r[convert.order+2]
> Raw `SnapshotCutResponse` wire data is converted to display data through the following ordered pipeline:
> 1. Collect all entities and edges across all processes into a single global entity map keyed by raw `EntityId`. Validate that every entity and scope carries a positive non-zero `backtrace_id`; throw with an explicit error message if any is missing or invalid.
> 2. Resolve edges: for `paired_with` edges, the `src` is looked up in the global entity map (cross-process); for all other kinds, `src` is scoped to the current process.
> 3. Merge channel pairs (`mergeChannelPairs`).
> 4. Merge RPC pairs (`mergeRpcPairs`).
> 5. Coalesce redundant `polls` edges (`coalesceContextEdges`).
> 6. Detect deadlock cycle membership (`detectCycleNodes`), marking `inCycle` on all entities in a cycle.

---

## Graph Node Merging

### Channel pair merging

> r[merge.channel]
> When a `paired_with` edge connects a TX entity (kind in `{mpsc_tx, broadcast_tx, watch_tx, oneshot_tx}`) to an RX entity (kind in `{mpsc_rx, broadcast_rx, watch_rx, oneshot_rx}`), the two nodes and the connecting edge MUST be replaced by a single synthetic `channel_pair` node.

> r[merge.channel.id]
> The merged node's ID MUST be `"pair:${txId}:${rxId}"`. The TX port ID MUST be `"${mergedId}:tx"` and the RX port ID MUST be `"${mergedId}:rx"`. Any edge that formerly connected to the TX or RX entity MUST be remapped to the merged node with the appropriate port ID.

> r[merge.channel.name]
> The merged node's name is derived from the TX entity's name: if it ends with `":tx"`, that suffix is stripped.

> r[merge.channel.status]
> The merged node's status is `{ label: "open", tone: "ok" }` if both component statuses have tone `"ok"`, and `{ label: "closed", tone: "neutral" }` otherwise. The merged node's `stat` and `statTone` are taken from the TX entity.

> r[merge.channel.guard]
> A TX or RX entity that is already part of a merged pair MUST NOT be merged a second time. Each channel endpoint participates in at most one merge.

### RPC pair merging

> r[merge.rpc]
> When a `paired_with` edge connects a `request` entity to a `response` entity (in either direction), and both belong to the same group under the active `groupBy` mode, the two nodes and the connecting edge MUST be replaced by a single synthetic `rpc_pair` node.

> r[merge.rpc.id]
> The merged node's ID MUST be `"rpc_pair:${reqId}:${respId}"`. The request port ID MUST be `"${mergedId}:req"` and the response port ID MUST be `"${mergedId}:resp"`. Any edge formerly connected to either component MUST be remapped to the merged node with the appropriate port ID.

> r[merge.rpc.name]
> The merged node's name is derived from the request entity's name: if it ends with `":req"`, that suffix is stripped.

> r[merge.rpc.status]
> The merged node's status is taken from the response entity if the response body is present, or `{ label: "in_flight", tone: "warn" }` if the response has no body.

> r[merge.rpc.group]
> If the request and response entities belong to different groups under the active `groupBy` mode, they MUST NOT be merged.

### Edge coalescing

> r[merge.coalesce]
> After channel and RPC pairs are merged, if a `polls` edge and any other edge kind both connect the same source-target pair, the `polls` edge MUST be suppressed. The richer structural or causal edge takes precedence.

### Deadlock cycle detection

> r[merge.cycles]
> After all merges, the `waiting_on` edges are traversed with DFS to find strongly-connected components. Every entity whose ID appears in a cycle MUST have `inCycle` set to `true`. Entities not in any cycle MUST have `inCycle` set to `false`.

---

## Graph Filtering

The graph filter is a space-separated list of tokens parsed from a single text input. Each token has the form `[sign]key:value`.

### Token syntax

> r[filter.token.syntax]
> A filter token has the form `[sign]key:value` where `sign` is `+` or `-` (absent means unsigned). Values may be double-quoted to include spaces or special characters. Within a quoted value, `\"` and `\\` are escape sequences.

> r[filter.token.tokenize]
> Tokens are separated by whitespace. Whitespace inside a quoted value does not split tokens. An unmatched `+` or `-` prefix with no key-value following it is not a valid token.

### Signed filter tokens (inclusion/exclusion)

Signed tokens form an allowlist (`+`) or denylist (`-`). Multiple tokens of the same sign and axis combine as a union (OR). If any `+` token is present for an axis, only entities matching at least one of the `+` values on that axis are shown.

> r[filter.axis.node+2]
> `+node:<id>` / `-node:<id>` — include or exclude the entity with the given raw `EntityId`. The key may also be spelled `id`.

> r[filter.axis.location+2]
> `+location:<src>` / `-location:<src>` — include or exclude entities whose top application frame's `"source_file:line"` matches the given string. The key may also be spelled `source`. Entities with no top application frame are treated as non-matching for this axis.

> r[filter.axis.crate+2]
> `+crate:<name>` / `-crate:<name>` — include or exclude entities whose top application frame's `crate_name` matches the given name. Entities with no top application frame are treated as non-matching for this axis.

> r[filter.axis.module.bt]
> `+module:<path>` / `-module:<path>` — include or exclude entities whose top application frame's `module_path` (the Rust module path within the crate, e.g. `server::handler`) matches the given string. Entities with no top application frame are treated as non-matching for this axis.

> r[filter.axis.process]
> `+process:<id>` / `-process:<id>` — include or exclude entities belonging to the process with the given `processId` string.

> r[filter.axis.kind]
> `+kind:<kind>` / `-kind:<kind>` — include or exclude entities whose canonical kind matches the given string.

### Unsigned control tokens

> r[filter.control.focus+2]
> `focus:<id>` (also `subgraph:<id>`) — after all axis filters are applied, restrict the visible graph to the connected subgraph reachable from the entity with the given raw `EntityId` via any edge in either direction (BFS). Entities not reachable from the focus node are hidden.

> r[filter.control.loners]
> `loners:on` / `loners:off` — when `off`, entities that have no edges to any other visible entity MUST be hidden from the graph. The default behavior (no token) is equivalent to `loners:on`.

> r[filter.control.colorby+2]
> `colorBy:process` — color entity nodes by their process membership. `colorBy:crate` — color entity nodes by the `crate_name` of their top application frame; entities with no top application frame receive the default color. When absent, all nodes use the default color.

> r[filter.control.groupby+2]
> `groupBy:process` / `groupBy:crate` — render entities inside labeled subgraph boxes grouped by process or by the `crate_name` of their top application frame. `groupBy:none` removes grouping. Entities with no top application frame are placed in an implicit ungrouped region when grouping by crate. Grouping also affects RPC pair merging: request and response entities in different groups are not merged.

> r[filter.control.labelby+2]
> `labelBy:process` / `labelBy:crate` / `labelBy:location` — display a secondary label on each entity card showing the process name, the `crate_name` of the top application frame, or the `source_file:line` of the top application frame respectively. Entities with no top application frame show no secondary label.

### Filter application order

> r[filter.order]
> Filters MUST be applied in the following order:
> 1. Apply signed axis filters (include/exclude by node, location, crate, module, process, kind).
> 2. Collapse edges through any newly-hidden nodes (see `f[graph.collapse]`).
> 3. If `loners:off`, remove entities with no remaining edges.
> 4. If a `focus` token is present, restrict to the connected subgraph of the focus node.

### Edge collapsing through hidden nodes

> r[graph.collapse]
> When entities are hidden by filtering, any edge that passed through a hidden node would disappear from the graph, potentially breaking the visual path between visible nodes. To preserve connectivity: for each pair of visible nodes that are connected through one or more hidden intermediate nodes (following any edge in either direction), a synthetic `polls` edge MUST be created between them, unless a direct visible edge already exists between that pair.

> r[graph.collapse.id]
> A synthetic collapsed edge MUST have ID `"collapsed-${left}-${right}"` where `left` and `right` are the lexicographically ordered source and target IDs.

> r[graph.collapse.no-dup]
> A synthetic collapsed edge MUST NOT be created if a direct visible edge already connects that same node pair.

### Autocomplete

> r[filter.suggest]
> The filter input MUST provide autocomplete suggestions based on the current draft token. Suggestions are ranked by prefix match, substring match, and fuzzy subsequence match (in that order). Suggestions that are already present as committed tokens MUST be omitted.

> r[filter.suggest.fragment+2]
> Suggestions are generated against the in-progress fragment (the token currently being typed). When the fragment is empty or has no `:`, top-level operator and control tokens are suggested. When the fragment begins with `+` or `-` and no `:`, signed axis key suggestions are offered. When a `:` is present, value completions for the given key are offered using available entity IDs, process IDs, kinds, and — for `crate`, `module`, and `location` axes — the crate names, module paths, and source locations from the top application frames in the current cut's `top_frames` map.

---

## Backtrace Display

> r[display.backtrace.cache]
> The frontend MUST cache resolved `BacktraceResponse` values keyed by `(conn_id, backtrace_id)`. A cached result MUST be reused without re-fetching for the lifetime of the dashboard session.

> r[display.backtrace.fetch]
> Backtrace resolution MUST be triggered by explicit user interaction — expanding an entity or scope card, or activating a dedicated call-stack indicator — rather than eagerly for all visible entities. The UI MUST reflect the loading state while a fetch is in progress.

> r[display.backtrace.render.resolved]
> Each resolved frame MUST be displayed showing the demangled `function_name`, the `crate_name`, and the `source_file:line` (omitting the line suffix if `line` is absent).

> r[display.backtrace.render.unresolved]
> Each unresolved frame MUST be displayed with a distinct visual indicator (e.g. a warning badge) and MUST show the raw `module_path` and `rel_pc` so the user can diagnose why symbolication failed.

---

## Recording

### Session lifecycle

> r[recording.lifecycle]
> The recording session follows a strict state machine:
> - **idle**: no session exists. `GET /api/record/current` returns no `session`.
> - **recording**: a session is active. `status` is `"recording"`.
> - **stopped**: the session has ended. `status` is `"stopped"`. Frame data is available for scrubbing.

### Frame capture

> r[recording.frame]
> Each frame in a recording session is a complete `SnapshotCutResponse` captured at `interval_ms` milliseconds since the previous frame. A `FrameSummary` carries `frame_index`, `captured_at_unix_ms`, `process_count`, and `capture_duration_ms`.

### Union layout

> r[recording.union]
> To support frame scrubbing without re-laying-out on every frame, the dashboard MUST pre-compute a **union layout**: the union of all nodes and edges that appear in any processed frame. This union is laid out once by the graph layout engine. Node positions from the union layout are reused for all frames.

> r[recording.union.presence]
> For each node and each edge in the union, the set of frame indices in which it is present MUST be tracked. This enables efficient per-frame visibility queries.

> r[recording.union.ghost]
> In ghost mode, nodes and edges that exist in the union but are absent from the current frame MUST be rendered translucently ("ghost" style) at their union layout positions. This preserves spatial stability across frames.

> r[recording.union.downsample]
> The dashboard MAY downsample frames by processing only every N-th frame (plus first and last) to reduce fetch load. The downsample interval is configurable. Nearest-frame snapping MUST be used when displaying a scrub position that falls between processed frames.

### Frame change detection

> r[recording.changes]
> The dashboard MUST compute a list of frames in which the graph topology changed (nodes or edges appeared or disappeared relative to the previous processed frame). Only these change frames need to be represented as distinct scrub positions in the timeline.

### Export and import

> r[recording.export]
> A recording session MUST be exportable as a self-contained binary blob via `GET /api/record/current/export`.

> r[recording.import]
> An exported recording MAY be imported back into the dashboard via `POST /api/record/import`, replacing the current session.
